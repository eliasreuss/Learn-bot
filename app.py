# streamlit_app.py
import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.prompts import ChatPromptTemplate

load_dotenv()

st.set_page_config(page_title="Inact Learn Chatbot", page_icon="游눫")

#Font og farve
st.markdown("""
    <style>
    /* --- Importer og anvend Poppins font --- */
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600&display=swap');
    
    html, body, [class*="st-"], [class*="css-"] {
        font-family: 'Poppins', sans-serif;
    }
    </style>
    """, unsafe_allow_html=True)


@st.cache_resource
def get_vectorstore():
    embeddings = OpenAIEmbeddings(openai_api_key=os.environ["OPENAI_API_KEY"])
    return Chroma(persist_directory="chromadb", embedding_function=embeddings)

@st.cache_resource
def get_llm():
    return ChatOpenAI(temperature=0, openai_api_key=os.environ["OPENAI_API_KEY"], model_name="gpt-3.5-turbo")

prompt_template = ChatPromptTemplate.from_template(
    "Du er en AI-assistent for Inact. Dit m친l er at levere pr칝cise svar og yderst relevante anbefalinger.\n\n"
    "### Opgave 1: Svar p친 sp칮rgsm친let\n"
    "Brug 'VIDENSBASE KONTEKST' til at formulere et grundigt og klart svar p친 brugerens sp칮rgsm친l. Hvis der er en trin-for-trin guide, skal den pr칝senteres som en nummereret liste.\n\n"
    "### Opgave 2: Vurder og Anbefal L칝ringsressourcer\n"
    "Du har modtaget en liste af *potentielle* l칝ringsressourcer i 'L칁RINGSRESSOURCE KONTEKST'. Din opgave er at agere som et intelligent filter.\n"
    "1.  **Vurder Relevans:** Gennemg친 HVER ressource i 'L칁RINGSRESSOURCE KONTEKST' og vurder, om den er direkte relevant for brugerens specifikke sp칮rgsm친l.\n"
    "2.  **Lav Anbefalinger:** Hvis du finder en eller flere relevante ressourcer, SKAL du tilf칮je en sektion til sidst i dit svar med overskriften: '**Anbefalet L칝ring:**'\n"
    "3.  **Formater Kun De Relevante:** For KUN de ressourcer, du har vurderet som relevante, skal du formatere dem som et punkt med et link, f.eks.: `* Se vores video: [Titel p친 video](URL)`.\n"
    "4.  **Hvis Intet er Relevant:** Hvis INGEN af ressourcerne i 'L칁RINGSRESSOURCE KONTEKST' er relevante for sp칮rgsm친let, skal du IKKE tilf칮je 'Anbefalet L칝ring'-sektionen.\n\n"
    "---"
    "\n\n**L칁RINGSRESSOURCE KONTEKST (Potentielle kandidater til anbefaling):**\n{resource_context}\n\n"
    "**VIDENSBASE KONTEKST (Til at formulere svar):**\n{knowledge_context}\n\n"
    "**Sp칮rgsm친l:** {question}\n\n"
    "**Svar:**"
)

# Initialisering
db = get_vectorstore()
llm = get_llm()

if "messages" not in st.session_state:
    st.session_state.messages = []

# Brug st.markdown for at matche designet
st.markdown(
    """
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600&display=swap');
    .custom-header {
        font-family: 'Poppins', sans-serif;
        color: #304642;
        font-size: 2rem;
        font-weight: 600;
        text-align: center;
        margin-top: 2.5rem;
        margin-bottom: 2.5rem;
    }
    .gertrud-orange { color: #FF5A00; }
    </style>
    <div class="custom-header">Hello, <span class="gertrud-orange">Gertrud</span>. How can I help you today?</div>
    """,
    unsafe_allow_html=True
)

# Chat logik med placeholder

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_question := st.chat_input("How do i create an Insight in Inact Now?"):
    st.session_state.messages.append({"role": "user", "content": user_question})
    with st.chat_message("user"):
        st.markdown(user_question)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("T칝nker...") 

        resource_retriever = db.as_retriever(search_kwargs={"k": 5, "filter": {"doc_type": "resource"}})
        resource_docs = resource_retriever.get_relevant_documents(user_question)
        resource_context = "\n\n---\n\n".join([doc.page_content for doc in resource_docs])

        knowledge_retriever = db.as_retriever(search_kwargs={"k": 3, "filter": {"doc_type": "knowledge"}})
        knowledge_docs = knowledge_retriever.get_relevant_documents(user_question)
        knowledge_context = "\n\n---\n\n".join([doc.page_content for doc in knowledge_docs])
        
        chain = prompt_template | llm
        response = chain.invoke({
            "resource_context": resource_context,
            "knowledge_context": knowledge_context,
            "question": user_question
        })
        answer = response.content
        
        message_placeholder.markdown(answer)
    st.session_state.messages.append({"role": "assistant", "content": answer})